# bot.py
import os
import logging
import random
import asyncio

from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

from modules.sentiment_analysis import analyze_sentiment
from modules.auto_responses import get_autoresponder
from modules.speech_to_text import transcribe_audio
from modules.image_analysis import analyze_image

# -------------------------------------------------------------------
# LOGGING
# -------------------------------------------------------------------
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO,
)
logger = logging.getLogger(__name__)

# -------------------------------------------------------------------
# CONFIGURACIÃ“N
# -------------------------------------------------------------------
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
auto_responder = get_autoresponder("data/responses_dataset.csv")

WELCOME_MESSAGES = [
    "ğŸ‘‹ Â¡Hola! Soy Pulsett Bot ğŸ¤–. Estoy acÃ¡ para acompaÃ±arte, Â¿cÃ³mo te sentÃ­s hoy?",
    "ğŸŒˆ Â¡Bienvenido! Soy Pulsett Bot. Podemos charlar sobre lo que necesites ğŸ’¬",
    "ğŸ’™ Â¡Hola! Me alegra verte por acÃ¡. Contame, Â¿cÃ³mo va tu dÃ­a?",
    "ğŸ¤— Â¡Hola! Soy tu compaÃ±ero emocional digital. Estoy acÃ¡ para escucharte.",
]

NEUTRAL_BASE = [
    "ğŸ™‚ Gracias por compartir cÃ³mo te sentÃ­s. A veces no tenerlo del todo claro tambiÃ©n estÃ¡ bien.",
    "ğŸ§  Entiendo, y aprecio que lo compartas conmigo. Si querÃ©s charlar un poco mÃ¡s, estoy acÃ¡.",
    "ğŸ˜Œ Gracias por contarme eso. Poner en palabras lo que sentimos ya es un gran paso.",
]

POSITIVE_BASE = [
    "ğŸŒŸ QuÃ© alegrÃ­a leerte asÃ­. Me encanta saber que estÃ¡s bien, seguÃ­ aprovechando ese estado de Ã¡nimo para recargar energÃ­a ğŸ’ª.",
    "ğŸ˜„ Me pone muy contento ver tu buena energÃ­a. DisfrutÃ¡ este momento y hacÃ© algo que te haga sonreÃ­r.",
    "âœ¨ Me encanta leer eso. Cada dÃ­a con una sonrisa es una victoria, seguÃ­ asÃ­ ğŸ’™.",
]

NEGATIVE_BASE = [
    "ğŸ’™ Lamento que estÃ©s pasando por un momento difÃ­cil. A veces no estar bien tambiÃ©n estÃ¡ bien, y hablar de lo que sentimos puede ayudar.",
    "ğŸ˜” Entiendo cÃ³mo te sentÃ­s. No estÃ¡s solo en esto; estoy acÃ¡ para escucharte si querÃ©s contarme mÃ¡s.",
    "ğŸ¤ Gracias por confiarme lo que sentÃ­s. RecordÃ¡ que cada emociÃ³n es vÃ¡lida, incluso las mÃ¡s duras.",
]

SALUDOS = ["hola", "buenas", "hey", "holaa", "buen dÃ­a", "buenas tardes", "buenas noches"]


# -------------------------------------------------------------------
# COMANDOS
# -------------------------------------------------------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Mensaje inicial con bienvenida aleatoria."""
    message = random.choice(WELCOME_MESSAGES)
    await update.message.reply_text(message)
    context.user_data["active"] = True
    asyncio.create_task(inactivity_timer(update, context))


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ§  *Comandos disponibles:*\n\n"
        "/start - Iniciar conversaciÃ³n\n"
        "/help  - Mostrar ayuda\n\n"
        "PodÃ©s enviarme texto, audio o imÃ¡genes para analizar ğŸ˜Š",
        parse_mode="Markdown",
    )


# -------------------------------------------------------------------
# MANEJADOR DE TEXTO
# -------------------------------------------------------------------
async def text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text_raw = update.message.text or ""
    text = text_raw.lower().strip()

    # Saludo explÃ­cito
    if any(text == s or text.startswith(s + " ") for s in SALUDOS):
        await update.message.reply_text(
            "ğŸ‘‹ Â¡Hola! Soy Pulsett Bot ğŸ¤–, tu compaÃ±ero emocional. Â¿CÃ³mo te sentÃ­s hoy?"
        )
        context.user_data["last_emotion"] = "neutral"
        return

    # AnÃ¡lisis de sentimiento
    sent = analyze_sentiment(text_raw)
    tone = sent["label"].lower()
    last_tone = context.user_data.get("last_emotion")

    reply = f"ğŸ” *AnÃ¡lisis de sentimiento:* {sent['label'].capitalize()}.\n\n"

    if tone == "negativo":
        if any(pal in text for pal in ["solo", "sola", "soledad"]):
            reply += (
                "ğŸ’™ Sentirse solo puede ser muy duro. Gracias por animarte a decirlo. "
                "No estÃ¡s solo acÃ¡, podemos charlar todo lo que necesites."
            )
        elif last_tone == "positivo":
            reply += (
                "ğŸ˜” Noto un cambio en tu Ã¡nimo. EstÃ¡ bien, todos tenemos altibajos. "
                "Si querÃ©s hablar de eso, te escucho ğŸ’¬."
            )
        else:
            reply += random.choice(NEGATIVE_BASE)

    elif tone == "positivo":
        if last_tone == "negativo":
            reply += (
                "ğŸ’ª Me alegra mucho ver que te sentÃ­s mejor. Es un paso importante hacia adelante, "
                "bien por vos ğŸ™Œ."
            )
        else:
            reply += random.choice(POSITIVE_BASE)

    else:  # neutral
        auto_reply = (
            auto_responder.predict_response(text_raw)
            if auto_responder is not None
            else None
        )
        if auto_reply:
            reply += auto_reply
        else:
            reply += random.choice(NEUTRAL_BASE)

    context.user_data["last_emotion"] = tone
    await update.message.reply_text(reply, parse_mode="Markdown")


# -------------------------------------------------------------------
# MANEJADOR DE AUDIO
# -------------------------------------------------------------------
async def voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await update.message.voice.get_file()
    local_ogg = f"temp_{update.message.message_id}.oga"
    await file.download_to_drive(custom_path=local_ogg)

    await update.message.reply_text(
        "ğŸ§ Estoy escuchando tu mensaje... un momento por favor â³"
    )

    # TranscripciÃ³n (puede fallar silenciosamente si no hay ffmpeg/whisper/etc.)
    text = transcribe_audio(local_ogg)

    if os.path.exists(local_ogg):
        os.remove(local_ogg)

    if not text or not text.strip():
        await update.message.reply_text(
            "ğŸ˜• No logrÃ© entender tu audio. Â¿PodrÃ­as intentar de nuevo o escribirme cÃ³mo te sentÃ­s?"
        )
        return

    sent = analyze_sentiment(text)
    tone = sent["label"].lower()
    auto_reply = (
        auto_responder.predict_response(text) if auto_responder is not None else None
    )

    reply = "ğŸ§  *AnÃ¡lisis de tu mensaje de voz:*\n\n"

    if tone == "positivo":
        reply += random.choice(POSITIVE_BASE)
    elif tone == "negativo":
        reply += random.choice(NEGATIVE_BASE)
    else:
        reply += random.choice(NEUTRAL_BASE)

    if auto_reply:
        reply += f"\n\nğŸ—£ {auto_reply}"

    await update.message.reply_text(reply, parse_mode="Markdown")


# -------------------------------------------------------------------
# MANEJADOR DE IMÃGENES
# -------------------------------------------------------------------
async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await update.message.photo[-1].get_file()
    local_jpg = f"temp_photo_{update.message.message_id}.jpg"
    await file.download_to_drive(custom_path=local_jpg)

    await update.message.reply_text(
        "ğŸ–¼ï¸ Analizando la imagen... un momento por favor âšª"
    )

    res = analyze_image(local_jpg)

    if os.path.exists(local_jpg):
        os.remove(local_jpg)

    emotion = res.get("emotion", "unknown").lower()

    reply_map = {
        "happy": "ğŸ™‚ Parece que hay una emociÃ³n positiva en la imagen.",
        "sad": "ğŸ’™ La imagen transmite tristeza. Â¿QuerÃ©s contarme quÃ© pasÃ³?",
        "angry": "ğŸ˜  Veo enojo o frustraciÃ³n en la imagen.",
        "surprise": "ğŸ˜® Algo inesperado parece estar ocurriendo.",
        "fear": "ğŸ˜° La imagen expresa miedo o ansiedad.",
        "disgust": "ğŸ¤¢ Hay signos de disgusto o incomodidad.",
        "neutral": "ğŸ˜ La expresiÃ³n es bastante neutra.",
    }

    reply = (
        f"ğŸ–¼ï¸ *AnÃ¡lisis de imagen:*\n"
        f"EmociÃ³n detectada: *{emotion.capitalize()}*\n\n"
    )
    reply += reply_map.get(
        emotion,
        "ğŸ™‚ Estoy analizando la imagen, pero no estoy completamente seguro de la emociÃ³n.",
    )

    await update.message.reply_text(reply, parse_mode="Markdown")


# -------------------------------------------------------------------
# MENSAJE DE CIERRE AUTOMÃTICO
# -------------------------------------------------------------------
async def inactivity_timer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await asyncio.sleep(120)
    if context.user_data.get("active", False):
        await update.message.reply_text(
            "ğŸ’™ Gracias por charlar conmigo. RecordÃ¡ que tus emociones importan. "
            "Estoy acÃ¡ cuando necesites hablar ğŸ«‚"
        )
        context.user_data["active"] = False


# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------
def main():
    if TELEGRAM_TOKEN is None:
        print(
            "âŒ ERROR: Debes exportar TELEGRAM_TOKEN en las variables de entorno "
            "antes de ejecutar el bot."
        )
        return

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(MessageHandler(filters.VOICE, voice_handler))
    app.add_handler(MessageHandler(filters.PHOTO, photo_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_handler))

    print("âœ… Pulsett Bot iniciado. PresionÃ¡ Ctrl+C para detener.")
    app.run_polling()


if __name__ == "__main__":
    main()
