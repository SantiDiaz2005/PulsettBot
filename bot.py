# bot.py
import os
import logging
import random
import asyncio
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes
)

from modules.sentiment_analysis import analyze_sentiment
from modules.auto_responses import get_autoresponder
from modules.speech_to_text import transcribe_audio
from modules.image_analysis import analyze_image

# -------------------------------
# CONFIGURACIÃ“N DE LOGS
# -------------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Token desde variables de entorno
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")

# Dataset de auto-respuestas
auto_responder = get_autoresponder("data/responses_dataset.csv")

# -------------------------------
# RESPUESTAS BASE
# -------------------------------
WELCOME_MESSAGES = [
    "ğŸ‘‹ Â¡Hola! Soy Pulsett Bot ğŸ¤–. Estoy acÃ¡ para acompaÃ±arte, Â¿cÃ³mo te sentÃ­s hoy?",
    "ğŸŒˆ Â¡Bienvenido! Podemos charlar sobre lo que necesites ğŸ’¬",
    "ğŸ’™ Â¡Hola! Me alegra verte por acÃ¡. Contame, Â¿cÃ³mo va tu dÃ­a?",
    "ğŸ¤— Â¡Hola! Soy tu compaÃ±ero emocional digital. Estoy para escucharte."
]

NEUTRAL_BASE = [
    "ğŸ™‚ Gracias por compartir eso. Si querÃ©s hablar mÃ¡s, estoy acÃ¡.",
    "ğŸ§  Entiendo. Contame si querÃ©s profundizar un poco.",
    "ğŸ˜Œ Gracias por confiarme lo que sentÃ­s."
]

POSITIVE_BASE = [
    "ğŸŒŸ QuÃ© alegrÃ­a leerte asÃ­. DisfrutÃ¡ este buen momento ğŸ’ª.",
    "ğŸ˜„ Me pone contento tu buena energÃ­a.",
    "âœ¨ Me encanta leer eso. SeguÃ­ asÃ­ ğŸ’™."
]

NEGATIVE_BASE = [
    "ğŸ’™ Lamento que estÃ©s pasando por un momento difÃ­cil. Estoy con vos.",
    "ğŸ˜” Entiendo cÃ³mo te sentÃ­s. Si querÃ©s hablar, te escucho.",
    "ğŸ¤ Gracias por compartirlo. No estÃ¡s solo."
]

# -------------------------------
# COMANDOS
# -------------------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Mensaje inicial"""
    await update.message.reply_text(random.choice(WELCOME_MESSAGES))
    context.user_data["active"] = True
    asyncio.create_task(inactivity_timer(update, context))


async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ§  *Comandos disponibles:*\n\n"
        "/start - Iniciar conversaciÃ³n\n/help - Mostrar ayuda\n\n"
        "PodÃ©s enviarme texto, audio o imÃ¡genes ğŸ˜Š",
        parse_mode="Markdown"
    )

# -------------------------------
# MANEJADOR DE TEXTO
# -------------------------------
async def text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text_raw = update.message.text
    text = text_raw.lower().strip()

    # Detectar saludos
    SALUDOS = ["hola", "buenas", "hey", "holaa", "buen dÃ­a", "buenas tardes", "buenas noches"]
    if any(text.startswith(s) for s in SALUDOS):
        await update.message.reply_text("ğŸ‘‹ Â¡Hola! Â¿CÃ³mo te sentÃ­s hoy?")
        context.user_data["last_emotion"] = "neutral"
        return

    # AnÃ¡lisis emocional
    sent = analyze_sentiment(text_raw)
    tone = sent["label"].lower()
    last_tone = context.user_data.get("last_emotion", None)

    reply = f"ğŸ” *AnÃ¡lisis de sentimiento:* {sent['label'].capitalize()}.\n\n"

    # Respuestas segÃºn emociÃ³n
    if tone == "negativo":
        if last_tone == "positivo":
            reply += "ğŸ˜” Noto un cambio en tu Ã¡nimo. Si querÃ©s hablar, estoy acÃ¡."
        else:
            reply += random.choice(NEGATIVE_BASE)

    elif tone == "positivo":
        if last_tone == "negativo":
            reply += "ğŸ’ª Me alegra mucho ver que te sentÃ­s mejor ğŸ™Œ."
        else:
            reply += random.choice(POSITIVE_BASE)

    else:  # neutral
        auto_reply = auto_responder.predict_response(text_raw)
        if auto_reply:
            reply += auto_reply
        else:
            reply += random.choice(NEUTRAL_BASE)

    context.user_data["last_emotion"] = tone
    await update.message.reply_text(reply, parse_mode="Markdown")

# -------------------------------
# MANEJADOR DE AUDIO
# -------------------------------
async def voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await update.message.voice.get_file()
    local_ogg = f"temp_{update.message.message_id}.oga"
    await file.download_to_drive(custom_path=local_ogg)

    await update.message.reply_text("ğŸ§ Estoy escuchando tu mensaje... un momento â³")

    # Transcribir
    text = transcribe_audio(local_ogg)

    # Borrar archivo temporal
    if os.path.exists(local_ogg):
        os.remove(local_ogg)

    if not text or not text.strip():
        await update.message.reply_text(
            "ğŸ˜• No pude entender tu audio. Â¿PodÃ©s intentar de nuevo o escribirme cÃ³mo te sentÃ­s?"
        )
        return

    # Analizar sentimiento del texto transcrito
    sent = analyze_sentiment(text)
    tone = sent["label"].lower()

    reply = "ğŸ§  *AnÃ¡lisis de tu mensaje de voz:*\n\n"

    if tone == "positivo":
        reply += random.choice(POSITIVE_BASE)
    elif tone == "negativo":
        reply += random.choice(NEGATIVE_BASE)
    else:
        reply += random.choice(NEUTRAL_BASE)

    await update.message.reply_text(reply, parse_mode="Markdown")

# -------------------------------
# MANEJADOR DE IMAGEN
# -------------------------------
async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await update.message.photo[-1].get_file()
    local_jpg = f"temp_photo_{update.message.message_id}.jpg"
    await file.download_to_drive(custom_path=local_jpg)

    await update.message.reply_text("ğŸ–¼ï¸ Analizando la imagen... un momento âšª")

    res = analyze_image(local_jpg)
    if os.path.exists(local_jpg):
        os.remove(local_jpg)

    emotion = res.get("emotion", "unknown").lower()

    reply_map = {
        "happy": "ğŸ™‚ Parece una emociÃ³n positiva.",
        "sad": "ğŸ’™ La imagen transmite tristeza. Â¿QuerÃ©s contarme quÃ© pasÃ³?",
        "angry": "ğŸ˜  Veo enojo o frustraciÃ³n.",
        "surprise": "ğŸ˜® Algo inesperado parece haber ocurrido.",
        "fear": "ğŸ˜° La imagen muestra miedo o ansiedad.",
        "disgust": "ğŸ¤¢ Veo seÃ±ales de disgusto.",
        "neutral": "ğŸ˜ La expresiÃ³n es bastante neutra."
    }

    reply = f"ğŸ–¼ï¸ *AnÃ¡lisis de imagen:*\nEmociÃ³n detectada: **{emotion.capitalize()}**\n\n"
    reply += reply_map.get(emotion, "ğŸ™‚ No estoy completamente seguro de la emociÃ³n.")

    await update.message.reply_text(reply, parse_mode="Markdown")

# -------------------------------
# MENSAJE DE CIERRE AUTOMÃTICO
# -------------------------------
async def inactivity_timer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await asyncio.sleep(120)
    if context.user_data.get("active", False):
        await update.message.reply_text(
            "ğŸ’™ Gracias por charlar conmigo. Estoy acÃ¡ cuando necesites hablar ğŸ«‚"
        )
        context.user_data["active"] = False

# -------------------------------
# MAIN
# -------------------------------
def main():
    if TELEGRAM_TOKEN is None:
        print("âŒ ERROR: Falta la variable de entorno TELEGRAM_TOKEN.")
        return

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))

    app.add_handler(MessageHandler(filters.VOICE, voice_handler))
    app.add_handler(MessageHandler(filters.PHOTO, photo_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_handler))

    print("âœ… Pulsett Bot iniciado. PresionÃ¡ Ctrl+C para detener.")
    app.run_polling()


if __name__ == "__main__":
    main()

