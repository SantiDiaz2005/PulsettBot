# bot.py
import os
import logging
import random
import asyncio
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

from modules.sentiment_analysis import analyze_sentiment
from modules.auto_responses import get_autoresponder
from modules.speech_to_text import transcribe_audio
from modules.image_analysis import analyze_image

# ConfiguraciÃ³n de logs
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Token de entorno
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")

# Cargar el dataset de respuestas automÃ¡ticas
auto_responder = get_autoresponder("data/responses_dataset.csv")

# -------------- MENSAJES BASE --------------
WELCOME_MESSAGES = [
    "ğŸ‘‹ Â¡Hola! Soy Pulsett Bot ğŸ¤–. Estoy acÃ¡ para acompaÃ±arte, Â¿cÃ³mo te sentÃ­s hoy?",
    "ğŸŒˆ Â¡Bienvenido! Soy Pulsett Bot. Podemos charlar sobre lo que necesites ğŸ’¬",
    "ğŸ’™ Â¡Hola! Me alegra verte por acÃ¡. Contame, Â¿cÃ³mo va tu dÃ­a?",
    "ğŸ¤— Â¡Hola! Soy tu compaÃ±ero emocional digital. Estoy acÃ¡ para escucharte."
]

NEUTRAL_BASE = [
    "ğŸ™‚ Gracias por compartir cÃ³mo te sentÃ­s. A veces no tenerlo del todo claro tambiÃ©n estÃ¡ bien.",
    "ğŸ§  Entiendo, y aprecio que lo compartas conmigo. Si querÃ©s charlar un poco mÃ¡s, estoy acÃ¡.",
    "ğŸ˜Œ Gracias por contarme eso. Poner en palabras lo que sentimos ya es un gran paso."
]

POSITIVE_BASE = [
    "ğŸŒŸ QuÃ© alegrÃ­a leerte asÃ­. Me encanta saber que estÃ¡s bien, seguÃ­ aprovechando ese estado de Ã¡nimo para recargar energÃ­a ğŸ’ª.",
    "ğŸ˜„ Me pone muy contento ver tu buena energÃ­a. DisfrutÃ¡ este momento y hacÃ© algo que te haga sonreÃ­r.",
    "âœ¨ Me encanta leer eso. Cada dÃ­a con una sonrisa es una victoria, seguÃ­ asÃ­ ğŸ’™."
]

NEGATIVE_BASE = [
    "ğŸ’™ Lamento que estÃ©s pasando por un momento difÃ­cil. A veces no estar bien tambiÃ©n estÃ¡ bien, y hablar de lo que sentimos puede ayudar.",
    "ğŸ˜” Entiendo cÃ³mo te sentÃ­s. No estÃ¡s solo en esto; estoy acÃ¡ para escucharte si querÃ©s contarme mÃ¡s.",
    "ğŸ¤ Gracias por confiarme lo que sentÃ­s. RecordÃ¡ que cada emociÃ³n es vÃ¡lida, incluso las mÃ¡s duras."
]

# -------------- COMANDOS ----------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    message = random.choice(WELCOME_MESSAGES)
    await update.message.reply_text(message)
    context.user_data["active"] = True
    asyncio.create_task(inactivity_timer(update, context))

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ğŸ§  *Comandos disponibles:*\n\n"
        "/start - Iniciar conversaciÃ³n\n/help - Mostrar ayuda\n\n"
        "PodÃ©s enviarme texto, audio o imÃ¡genes para analizar ğŸ˜Š",
        parse_mode="Markdown"
    )

# -------------- MANEJADOR TEXTO --------------
async def text_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text_raw = update.message.text
    text = text_raw.lower().strip()

    SALUDOS = ["hola", "buenas", "hey", "holaa", "buen dÃ­a", "buenas tardes", "buenas noches"]
    if any(text.startswith(s) for s in SALUDOS):
        await update.message.reply_text(
            "ğŸ‘‹ Â¡Hola! Soy Pulsett Bot ğŸ¤–, tu compaÃ±ero emocional. Â¿CÃ³mo te sentÃ­s hoy?"
        )
        context.user_data["last_emotion"] = "neutral"
        return

    sent = analyze_sentiment(text_raw)
    tone = sent["label"].lower()
    last_tone = context.user_data.get("last_emotion", None)

    reply = f"ğŸ” *AnÃ¡lisis de sentimiento:* {sent['label'].capitalize()}.\n\n"

    if tone == "negativo":
        if any(p in text for p in ["solo", "sola", "soledad"]):
            reply += "ğŸ’™ Sentirse solo puede ser muy duro. Gracias por contarlo. Estoy acÃ¡ para vos."
        elif last_tone == "positivo":
            reply += "ğŸ˜” Veo un cambio en tu Ã¡nimo. EstÃ¡ bien tener altibajos. Â¿QuerÃ©s hablar sobre eso?"
        else:
            reply += random.choice(NEGATIVE_BASE)

    elif tone == "positivo":
        if last_tone == "negativo":
            reply += "ğŸ’ª QuÃ© bueno ver que estÃ¡s mejor. Me alegra mucho por vos ğŸ™Œ."
        else:
            reply += random.choice(POSITIVE_BASE)

    else:
        auto_reply = auto_responder.predict_response(text_raw) if auto_responder else None
        if auto_reply:
            reply += auto_reply
        else:
            reply += random.choice(NEUTRAL_BASE)

    context.user_data["last_emotion"] = tone
    await update.message.reply_text(reply, parse_mode="Markdown")

# -------------- MANEJADOR AUDIO --------------
async def voice_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        # Manejar tanto voice como audio
        if update.message.voice:
            file = await update.message.voice.get_file()
            file_extension = ".oga"
        elif update.message.audio:
            file = await update.message.audio.get_file()
            # Detectar extensiÃ³n del archivo de audio
            file_name = update.message.audio.file_name or "audio"
            if file_name.endswith(('.mp3', '.m4a', '.wav')):
                file_extension = os.path.splitext(file_name)[1]
            else:
                file_extension = ".oga"
        else:
            await update.message.reply_text("âŒ No se pudo procesar el mensaje de audio.")
            return

        local_audio = f"temp_{update.message.message_id}{file_extension}"
        
        try:
            await file.download_to_drive(custom_path=local_audio)
        except Exception as e:
            logger.error(f"Error al descargar audio: {e}")
            await update.message.reply_text("âŒ Error al descargar tu audio. Por favor, intentÃ¡ nuevamente.")
            return

        if not os.path.exists(local_audio):
            await update.message.reply_text("âŒ Error al descargar tu audio.")
            return

        await update.message.reply_text("ğŸ§ Estoy escuchando tu mensaje... un momento por favor â³")

        text = transcribe_audio(local_audio)

        # Limpiar archivo temporal
        if os.path.exists(local_audio):
            try:
                os.remove(local_audio)
            except Exception as e:
                logger.warning(f"No se pudo eliminar archivo temporal: {e}")

        if not text or not text.strip():
            await update.message.reply_text("ğŸ˜• No logrÃ© entender tu audio. Â¿PodÃ©s repetirlo o escribir cÃ³mo te sentÃ­s?")
            return

        sent = analyze_sentiment(text)
        tone = sent["label"].lower()

        reply = f"ğŸ§  **AnÃ¡lisis de tu mensaje de voz:**\n\n"
        reply += f"ğŸ“ *TranscripciÃ³n:* {text}\n\n"

        if tone == "positivo":
            reply += random.choice(POSITIVE_BASE)
        elif tone == "negativo":
            reply += random.choice(NEGATIVE_BASE)
        else:
            reply += random.choice(NEUTRAL_BASE)

        auto_reply = auto_responder.predict_response(text) if auto_responder else None
        if auto_reply and auto_reply != "ERROR_DATASET_VACIO":
            reply += f"\n\nğŸ—£ {auto_reply}"

        await update.message.reply_text(reply, parse_mode="Markdown")
        
    except Exception as e:
        logger.error(f"Error en voice_handler: {e}")
        await update.message.reply_text("âŒ OcurriÃ³ un error al procesar tu audio. Por favor, intentÃ¡ nuevamente.")

# -------------- MANEJADOR IMÃGENES --------------
async def photo_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    file = await update.message.photo[-1].get_file()
    local_jpg = f"temp_photo_{update.message.message_id}.jpg"
    await file.download_to_drive(custom_path=local_jpg)

    await update.message.reply_text("ğŸ–¼ï¸ Analizando la imagen... un momento por favor âšª")

    res = analyze_image(local_jpg)

    os.remove(local_jpg)

    emotion = res.get("emotion", "unknown").lower()

    reply_map = {
        "happy": "ğŸ™‚ Hay una emociÃ³n positiva en la imagen.",
        "sad": "ğŸ’™ Veo tristeza en la imagen. Â¿QuerÃ©s contarme quÃ© pasÃ³?",
        "angry": "ğŸ˜  La imagen muestra enojo.",
        "surprise": "ğŸ˜® Parece que algo inesperado sucediÃ³.",
        "fear": "ğŸ˜° Noto miedo o ansiedad.",
        "disgust": "ğŸ¤¢ Detecto signos de disgusto.",
        "neutral": "ğŸ˜ La expresiÃ³n es neutra."
    }

    reply = f"ğŸ–¼ï¸ *AnÃ¡lisis de imagen:*\nEmociÃ³n detectada: **{emotion.capitalize()}**\n\n"
    reply += reply_map.get(emotion, "ğŸ™‚ No estoy seguro de la emociÃ³n en la imagen.")

    await update.message.reply_text(reply, parse_mode="Markdown")

# -------------- INACTIVIDAD --------------
async def inactivity_timer(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await asyncio.sleep(120)
    if context.user_data.get("active", False):
        await update.message.reply_text(
            "ğŸ’™ Gracias por charlar conmigo. Estoy acÃ¡ cuando necesites hablar ğŸ«‚"
        )
        context.user_data["active"] = False

# -------------- MAIN --------------
def main():
    if TELEGRAM_TOKEN is None:
        print("âŒ ERROR: Debes exportar TELEGRAM_TOKEN en las variables de entorno.")
        return

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    # Capturar tanto mensajes de voz como archivos de audio
    app.add_handler(MessageHandler(filters.VOICE | filters.AUDIO, voice_handler))
    app.add_handler(MessageHandler(filters.PHOTO, photo_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_handler))

    print("âœ… Pulsett Bot iniciado. PresionÃ¡ Ctrl+C para detener.")
    app.run_polling()

if __name__ == "__main__":
    main()